[2025-01-30T09:33:16.504+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-30T09:33:16.568+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:33:16.580+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:33:16.580+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-01-30T09:33:16.805+0000] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): download_data> on 2019-06-02 00:00:00+00:00
[2025-01-30T09:33:16.821+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'homework_workflow_ingest', 'download_data', 'scheduled__2019-06-02T00:00:00+00:00', '--job-id', '41', '--raw', '--subdir', 'DAGS_FOLDER/homework_dag.py', '--cfg-path', '/tmp/tmpb061xwra']
[2025-01-30T09:33:16.825+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=204) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-01-30T09:33:16.824+0000] {standard_task_runner.py:105} INFO - Job 41: Subtask download_data
[2025-01-30T09:33:16.825+0000] {standard_task_runner.py:72} INFO - Started process 224 to run task
[2025-01-30T09:33:16.902+0000] {task_command.py:467} INFO - Running <TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [running]> on host 710324c6e27a
[2025-01-30T09:33:17.086+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='homework_workflow_ingest' AIRFLOW_CTX_TASK_ID='download_data' AIRFLOW_CTX_EXECUTION_DATE='2019-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2019-06-02T00:00:00+00:00'
[2025-01-30T09:33:17.087+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-30T09:33:17.113+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-01-30T09:33:17.114+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'curl -o /opt/***/data/yellow_2019-06_data.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet']
[2025-01-30T09:33:17.128+0000] {subprocess.py:99} INFO - Output:
[2025-01-30T09:33:17.149+0000] {subprocess.py:106} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2025-01-30T09:33:17.150+0000] {subprocess.py:106} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2025-01-30T09:33:23.538+0000] {subprocess.py:106} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 98.1M    0  206k    0     0   287k      0  0:05:50 --:--:--  0:05:50  286k 11 98.1M   11 10.8M    0     0  6266k      0  0:00:16  0:00:01  0:00:15 6264k 32 98.1M   32 31.5M    0     0  11.4M      0  0:00:08  0:00:02  0:00:06 11.4M 50 98.1M   50 49.5M    0     0  13.3M      0  0:00:07  0:00:03  0:00:04 13.3M 68 98.1M   68 67.4M    0     0  14.1M      0  0:00:06  0:00:04  0:00:02 14.1M 82 98.1M   82 81.2M    0     0  14.1M      0  0:00:06  0:00:05  0:00:01 16.1M100 98.1M  100 98.1M    0     0  15.3M      0  0:00:06  0:00:06 --:--:-- 18.9M
[2025-01-30T09:33:23.544+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-01-30T09:33:23.941+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-30T09:33:23.963+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=homework_workflow_ingest, task_id=download_data, run_id=scheduled__2019-06-02T00:00:00+00:00, execution_date=20190602T000000, start_date=20250130T093316, end_date=20250130T093323
[2025-01-30T09:33:26.552+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-30T09:33:26.703+0000] {taskinstance.py:3895} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-01-30T09:33:26.828+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
[2025-01-30T09:33:27.755+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-30T09:47:55.679+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-30T09:47:55.706+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:47:55.718+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:47:55.718+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-01-30T09:47:55.736+0000] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): download_data> on 2019-06-02 00:00:00+00:00
[2025-01-30T09:47:55.759+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=862) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-01-30T09:47:55.760+0000] {standard_task_runner.py:72} INFO - Started process 869 to run task
[2025-01-30T09:47:55.758+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'homework_workflow_ingest', 'download_data', 'scheduled__2019-06-02T00:00:00+00:00', '--job-id', '89', '--raw', '--subdir', 'DAGS_FOLDER/homework_dag.py', '--cfg-path', '/tmp/tmp5kb6w89t']
[2025-01-30T09:47:55.760+0000] {standard_task_runner.py:105} INFO - Job 89: Subtask download_data
[2025-01-30T09:47:55.845+0000] {task_command.py:467} INFO - Running <TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [running]> on host 710324c6e27a
[2025-01-30T09:47:55.948+0000] {abstractoperator.py:783} ERROR - Exception rendering Jinja template for task 'download_data', field 'bash_command'. Template: 'curl -o {{ var.value.AIRFLOW_HOME }}/data/{{ params.trip_class }}_{{ ds[:7] }}_data.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/{{ params.trip_class }}_tripdata_{{ ds[:7] }}.parquet'
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 775, in _do_render_template_fields
    rendered_content = self.render_template(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 171, in render_template
    return self._render(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 730, in _render
    return super()._render(template, context, dag=dag)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 127, in _render
    return render_template_to_string(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 301, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 296, in render_template
    return "".join(nodes)
           ^^^^^^^^^^^^^^
  File "<template>", line 15, in root
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 327, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/context.py", line 126, in __getattr__
    self.var = Variable.get(key, deserialize_json=self._deserialize_json)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable AIRFLOW_HOME does not exist'
[2025-01-30T09:47:55.950+0000] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3115, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context, jinja_env=jinja_env)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3534, in render_templates
    original_task.render_template_fields(context, jinja_env)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1438, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 775, in _do_render_template_fields
    rendered_content = self.render_template(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 171, in render_template
    return self._render(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 730, in _render
    return super()._render(template, context, dag=dag)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 127, in _render
    return render_template_to_string(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 301, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 296, in render_template
    return "".join(nodes)
           ^^^^^^^^^^^^^^
  File "<template>", line 15, in root
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 327, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/context.py", line 126, in __getattr__
    self.var = Variable.get(key, deserialize_json=self._deserialize_json)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable AIRFLOW_HOME does not exist'
[2025-01-30T09:47:55.961+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=homework_workflow_ingest, task_id=download_data, run_id=scheduled__2019-06-02T00:00:00+00:00, execution_date=20190602T000000, start_date=20250130T094755, end_date=20250130T094755
[2025-01-30T09:47:55.976+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-30T09:47:55.976+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 89 for task download_data ('Variable AIRFLOW_HOME does not exist'; 869)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3115, in _execute_task_with_callbacks
    task_orig = self.render_templates(context=context, jinja_env=jinja_env)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3534, in render_templates
    original_task.render_template_fields(context, jinja_env)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1438, in render_template_fields
    self._do_render_template_fields(self, self.template_fields, context, jinja_env, set())
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 775, in _do_render_template_fields
    rendered_content = self.render_template(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 171, in render_template
    return self._render(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/abstractoperator.py", line 730, in _render
    return super()._render(template, context, dag=dag)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/template/templater.py", line 127, in _render
    return render_template_to_string(template, context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 301, in render_template_to_string
    return render_template(template, cast(MutableMapping[str, Any], context), native=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 296, in render_template
    return "".join(nodes)
           ^^^^^^^^^^^^^^
  File "<template>", line 15, in root
  File "/home/airflow/.local/lib/python3.12/site-packages/jinja2/sandbox.py", line 327, in getattr
    value = getattr(obj, attribute)
            ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/context.py", line 126, in __getattr__
    self.var = Variable.get(key, deserialize_json=self._deserialize_json)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/variable.py", line 145, in get
    raise KeyError(f"Variable {key} does not exist")
KeyError: 'Variable AIRFLOW_HOME does not exist'
[2025-01-30T09:47:56.025+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-01-30T09:47:56.048+0000] {taskinstance.py:3895} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-01-30T09:47:56.052+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-30T09:58:37.785+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-01-30T09:58:37.821+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:58:37.830+0000] {taskinstance.py:2613} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [queued]>
[2025-01-30T09:58:37.831+0000] {taskinstance.py:2866} INFO - Starting attempt 1 of 1
[2025-01-30T09:58:37.910+0000] {taskinstance.py:2889} INFO - Executing <Task(BashOperator): download_data> on 2019-06-02 00:00:00+00:00
[2025-01-30T09:58:37.935+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=206) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-01-30T09:58:37.921+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'homework_workflow_ingest', 'download_data', 'scheduled__2019-06-02T00:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/homework_dag.py', '--cfg-path', '/tmp/tmp57vjpd49']
[2025-01-30T09:58:37.936+0000] {standard_task_runner.py:105} INFO - Job 7: Subtask download_data
[2025-01-30T09:58:37.936+0000] {standard_task_runner.py:72} INFO - Started process 218 to run task
[2025-01-30T09:58:38.031+0000] {task_command.py:467} INFO - Running <TaskInstance: homework_workflow_ingest.download_data scheduled__2019-06-02T00:00:00+00:00 [running]> on host 713eb9fcfb63
[2025-01-30T09:58:38.214+0000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='homework_workflow_ingest' AIRFLOW_CTX_TASK_ID='download_data' AIRFLOW_CTX_EXECUTION_DATE='2019-06-02T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2019-06-02T00:00:00+00:00'
[2025-01-30T09:58:38.215+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-01-30T09:58:38.245+0000] {subprocess.py:78} INFO - Tmp dir root location: /tmp
[2025-01-30T09:58:38.246+0000] {subprocess.py:88} INFO - Running command: ['/usr/bin/bash', '-c', 'curl -o /opt/***/data/yellow_2019-06_data.parquet https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-06.parquet']
[2025-01-30T09:58:38.268+0000] {subprocess.py:99} INFO - Output:
[2025-01-30T09:58:38.307+0000] {subprocess.py:106} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2025-01-30T09:58:38.307+0000] {subprocess.py:106} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2025-01-30T09:58:44.110+0000] {subprocess.py:106} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0 98.1M    0 96692    0     0   164k      0  0:10:10 --:--:--  0:10:10  164k 12 98.1M   12 12.5M    0     0  8173k      0  0:00:12  0:00:01  0:00:11 8171k 35 98.1M   35 35.0M    0     0  13.6M      0  0:00:07  0:00:02  0:00:05 13.6M 62 98.1M   62 61.4M    0     0  16.8M      0  0:00:05  0:00:03  0:00:02 16.8M 84 98.1M   84 82.8M    0     0  16.7M      0  0:00:05  0:00:04  0:00:01 16.7M 97 98.1M   97 95.6M    0     0  17.1M      0  0:00:05  0:00:05 --:--:-- 19.0M100 98.1M  100 98.1M    0     0  16.9M      0  0:00:05  0:00:05 --:--:-- 20.2M
[2025-01-30T09:58:44.120+0000] {subprocess.py:110} INFO - Command exited with return code 0
[2025-01-30T09:58:45.322+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-01-30T09:58:45.322+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=homework_workflow_ingest, task_id=download_data, run_id=scheduled__2019-06-02T00:00:00+00:00, execution_date=20190602T000000, start_date=20250130T095837, end_date=20250130T095845
[2025-01-30T09:58:46.483+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-01-30T09:58:46.658+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-01-30T09:58:47.941+0000] {standard_task_runner.py:217} INFO - Process not found (most likely exited), stop collecting metrics
